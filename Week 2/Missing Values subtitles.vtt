WEBVTT

1
00:00:08.720 --> 00:00:12.660
We're going to end this week of lecture
with a quick discussion of missing values.

2
00:00:12.660 --> 00:00:16.685
We've seen a preview of how Pandas
handles missing values using the None type

3
00:00:16.685 --> 00:00:18.820
and NumPy NaN values.

4
00:00:18.820 --> 00:00:21.800
Missing values are pretty common
in data cleaning activities.

5
00:00:21.800 --> 00:00:24.480
There are couple of caveats and
discussion points which we should address.

6
00:00:25.480 --> 00:00:28.960
First, the built in loading from
delimited files provides control for

7
00:00:28.960 --> 00:00:30.840
missing values in a few ways.

8
00:00:30.840 --> 00:00:34.380
The most germane of these,
is the na_values list,

9
00:00:34.380 --> 00:00:38.590
to indicate other strings which
could refer to missing values.

10
00:00:38.590 --> 00:00:41.580
Some of my sociologist colleagues for
instance, regularly

11
00:00:41.580 --> 00:00:46.120
use the value of 99 in binary categories
to indicate that there's no value.

12
00:00:46.120 --> 00:00:47.950
So this comes in handy.

13
00:00:47.950 --> 00:00:52.530
You can also use the na_filter option
to turn off white space filtering,

14
00:00:52.530 --> 00:00:55.480
if white space is an actual
value of interest.

15
00:00:55.480 --> 00:00:58.101
But in practice, this is pretty rare.

16
00:00:58.101 --> 00:01:01.759
In addition to rules controlling
how missing values might be loaded,

17
00:01:01.759 --> 00:01:06.230
it's sometimes useful to consider missing
values as actually having information.

18
00:01:06.230 --> 00:01:08.730
I'll give an example from my own research.

19
00:01:08.730 --> 00:01:11.730
I often deal with logs from
online learning systems.

20
00:01:11.730 --> 00:01:12.400
In particular,

21
00:01:12.400 --> 00:01:17.390
I've done a couple of projects looking
at video use in lecture capture systems.

22
00:01:17.390 --> 00:01:21.590
In these systems it's common for the player
for have a heartbeat functionality where

23
00:01:21.590 --> 00:01:25.450
playback statistics are sent to the server
every so often, maybe every 30 seconds.

24
00:01:26.530 --> 00:01:29.950
These heartbeats can get big as they can
carry the whole state of the playback

25
00:01:29.950 --> 00:01:34.270
system, such as where the video play
head is at, where the video size is,

26
00:01:34.270 --> 00:01:37.420
which video is being rendered to
the screen, how loud the volume is, etc.

27
00:01:38.880 --> 00:01:41.300
If we load the data file log.txt,

28
00:01:41.300 --> 00:01:44.070
we can see an example of
what this might look like.

29
00:01:44.070 --> 00:01:48.520
In this data the first column is
a timestamp in the Unix epoch format.

30
00:01:48.520 --> 00:01:51.900
The next column is the user name followed
by a web page they're visiting and

31
00:01:51.900 --> 00:01:52.940
the video that they're playing.

32
00:01:54.190 --> 00:01:56.710
Each row of the DataFrame
has a playback position.

33
00:01:56.710 --> 00:01:59.960
And we can see that as the playback
position increases by one,

34
00:01:59.960 --> 00:02:02.210
the time stamp increases
by about 30 seconds.

35
00:02:03.300 --> 00:02:04.820
Except for user Bob.

36
00:02:04.820 --> 00:02:07.060
It turns out that Bob has
paused his playback so

37
00:02:07.060 --> 00:02:10.530
as time increases the playback
position doesn't change.

38
00:02:10.530 --> 00:02:14.960
Note too how difficult it is for us to try
and derive this knowledge from the data,

39
00:02:14.960 --> 00:02:18.470
because it's not sorted by time
stamp as one might expect.

40
00:02:18.470 --> 00:02:22.240
This is actually not uncommon on systems
which have a high degree of parallelism.

41
00:02:24.000 --> 00:02:27.420
There are a lot of missing values
in the paused and volume columns.

42
00:02:27.420 --> 00:02:30.380
It's not efficient to send this
information across the network if it

43
00:02:30.380 --> 00:02:31.320
hasn't changed.

44
00:02:31.320 --> 00:02:34.740
So this particular system just inserts
null values into the database if

45
00:02:34.740 --> 00:02:35.479
there's no changes.

46
00:02:36.590 --> 00:02:38.850
One of the handy functions
that Pandas has for

47
00:02:38.850 --> 00:02:43.230
working with missing values is
the filling function, fillna.

48
00:02:43.230 --> 00:02:45.780
This function takes a number or
parameters, for

49
00:02:45.780 --> 00:02:49.210
instance, you could pass in a single
value which is called a scalar value

50
00:02:49.210 --> 00:02:51.650
to change all of the missing
data to one value.

51
00:02:51.650 --> 00:02:55.470
This isn't really applicable in this case,
but it's a pretty common use case.

52
00:02:55.470 --> 00:02:57.720
Next up though is the method parameter.

53
00:02:57.720 --> 00:03:00.780
The two common fill values are ffill and
bfill.

54
00:03:00.780 --> 00:03:04.490
ffill is for forward filling and
it updates an na value for

55
00:03:04.490 --> 00:03:07.650
a particular cell with the value
from the previous row.

56
00:03:07.650 --> 00:03:10.770
It's important to note that your
data needs to be sorted in order for

57
00:03:10.770 --> 00:03:13.250
this to have the effect you might want.

58
00:03:13.250 --> 00:03:17.210
Data that comes from traditional database
management systems usually has no

59
00:03:17.210 --> 00:03:19.630
order guarantee, just like this data.

60
00:03:19.630 --> 00:03:20.300
So be careful.

61
00:03:21.810 --> 00:03:25.360
In Pandas we can sort either by index or
by values.

62
00:03:25.360 --> 00:03:28.780
Here we'll just promote the time stamp
to an index then sort on the index.

63
00:03:30.080 --> 00:03:33.140
If we look closely at the output
though we'll notice that the index

64
00:03:33.140 --> 00:03:34.560
isn't really unique.

65
00:03:34.560 --> 00:03:37.830
Two users seem to be able to use
the system at the same time.

66
00:03:37.830 --> 00:03:39.620
Again, a very common case.

67
00:03:40.770 --> 00:03:44.380
Let's reset the index, and
use some multi-level indexing instead, and

68
00:03:44.380 --> 00:03:48.200
promote the user name to a second level
of the index to deal with that issue.

69
00:03:49.520 --> 00:03:50.918
Now that we have the data indexed and

70
00:03:50.918 --> 00:03:55.550
sorted appropriately, we can fill
the missing datas using ffill.

71
00:03:55.550 --> 00:03:57.800
It's good to remember when
dealing with missing values so

72
00:03:57.800 --> 00:03:59.570
you can deal with individual columns or

73
00:03:59.570 --> 00:04:02.860
sets of columns by projecting them
just as we spoke about earlier.

74
00:04:02.860 --> 00:04:05.920
So you don't have to fix all
missing values in one command.

75
00:04:06.940 --> 00:04:10.520
It's sometimes useful to use forward
filling, sometimes backwards filling, and

76
00:04:10.520 --> 00:04:12.686
sometimes useful to just
use a single number.

77
00:04:12.686 --> 00:04:16.900
More recently, the Pandas team introduced
a method of filling missing values with

78
00:04:16.900 --> 00:04:19.960
a series which is the same
length as your DataFrame.

79
00:04:19.960 --> 00:04:22.730
This makes it easy to derive values
which are missing if you have

80
00:04:22.730 --> 00:04:24.160
the underlying to do so.

81
00:04:24.160 --> 00:04:26.880
For instance, if you're dealing with
receipts and you have a column for

82
00:04:26.880 --> 00:04:30.770
final price and a column for discount but
are missing information from the original

83
00:04:30.770 --> 00:04:34.104
price column, you can fill this
automatically using fillna.

84
00:04:35.650 --> 00:04:37.510
One last note on missing values.

85
00:04:37.510 --> 00:04:39.760
When you use statistical
functions on DataFrames,

86
00:04:39.760 --> 00:04:42.670
these functions typically
ignore missing values.

87
00:04:42.670 --> 00:04:45.740
For instance if you try and
calculate the mean value of a DataFrame,

88
00:04:45.740 --> 00:04:49.360
the underlying NumPy function
will ignore missing values.

89
00:04:49.360 --> 00:04:50.940
This is usually what you want but

90
00:04:50.940 --> 00:04:53.360
you should be aware that
values are being excluded.
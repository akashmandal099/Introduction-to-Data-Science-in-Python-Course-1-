WEBVTT

1
00:00:09.315 --> 00:00:12.588
Now that we've covered many of the
mechanics of Pandas, I want to stop and

2
00:00:12.588 --> 00:00:15.590
talk for
a moment about data types and scales.

3
00:00:15.590 --> 00:00:19.140
We've already seen that Pandas supports
a number of different computational data

4
00:00:19.140 --> 00:00:22.510
types such as strings, integers and
floating point numbers.

5
00:00:22.510 --> 00:00:25.120
What this doesn't capture is what
we call the scale of the data.

6
00:00:26.190 --> 00:00:27.930
Let's say that we have
a DataFrame of students and

7
00:00:27.930 --> 00:00:31.010
their academic levels such as being
in grade 1 or grade 2 and grade 3.

8
00:00:31.010 --> 00:00:35.300
There's a difference between a student in
grade 1 and a student in grade 2, the same

9
00:00:35.300 --> 00:00:39.200
as the difference between a student
in grade 8 and a student in grade 9.

10
00:00:39.200 --> 00:00:41.630
Well let's think about the final
exam scores these students might get

11
00:00:41.630 --> 00:00:42.780
on assignments.

12
00:00:42.780 --> 00:00:44.530
Is the difference between an A and

13
00:00:44.530 --> 00:00:48.970
an A minus the same as the difference
between an A minus and a B plus?

14
00:00:48.970 --> 00:00:51.640
At the University of Michigan at least,
the answer is usually no.

15
00:00:53.330 --> 00:00:55.870
We've intuitively seen
some different scales, and

16
00:00:55.870 --> 00:00:59.170
as we move through data cleaning and
statistical analysis and

17
00:00:59.170 --> 00:01:03.430
machine learning, it's important to
clarify our knowledge and terminology.

18
00:01:03.430 --> 00:01:06.330
As a data scientist there four
scales that it's worth knowing.

19
00:01:07.410 --> 00:01:08.785
The first is a ratio scale.

20
00:01:08.785 --> 00:01:13.150
In the ratio scale the measurements units
are equally spaced and mathematical

21
00:01:13.150 --> 00:01:17.430
operations, such as subtract, division,
and multiplication are all valid.

22
00:01:17.430 --> 00:01:20.809
Good examples of ratio scale measurements
might be the height and weight.

23
00:01:21.970 --> 00:01:23.880
The next scale is the interval scale.

24
00:01:23.880 --> 00:01:26.620
In the interval scale the measurement
units are equally spaced

25
00:01:26.620 --> 00:01:27.930
like the ratio scale.

26
00:01:27.930 --> 00:01:30.030
But there's no clear absence of value.

27
00:01:30.030 --> 00:01:34.440
That is there isn't a true zero, and so
operation such as multiplication and

28
00:01:34.440 --> 00:01:36.049
division are not valid.

29
00:01:37.080 --> 00:01:40.860
An example of the interval scale might be
the temperatures measured in Celsius or

30
00:01:40.860 --> 00:01:41.800
Fahrenheit.

31
00:01:41.800 --> 00:01:44.045
Since there's never
an absence of temperature and

32
00:01:44.045 --> 00:01:46.650
0 degrees is a meaningful
value of temperature.

33
00:01:48.430 --> 00:01:52.810
The direction on a campus might be another
good example where 0 degrees on the campus

34
00:01:52.810 --> 00:01:54.760
doesn't indicate a lack of direction.

35
00:01:56.170 --> 00:01:58.850
For most of the work you do at data
mining, the differences between

36
00:01:58.850 --> 00:02:01.830
the ratio and interval scales
might not be clearly apparent or

37
00:02:01.830 --> 00:02:04.130
important than the algorithm
you're applying.

38
00:02:04.130 --> 00:02:06.990
But it's important to have this clear in
your mind when you're applying advanced

39
00:02:06.990 --> 00:02:08.040
statistical tests.

40
00:02:09.340 --> 00:02:13.160
The next scale is the ordinal scale,
and this is also important.

41
00:02:13.160 --> 00:02:16.270
In the ordinal scale the order
of values is important but

42
00:02:16.270 --> 00:02:19.770
the differences between the values
are not equally spaced.

43
00:02:19.770 --> 00:02:23.260
Here the a grading method that is used in
many classes at the University of Michigan

44
00:02:23.260 --> 00:02:27.500
as a great example, where letter grades
are given with pluses and minuses.

45
00:02:27.500 --> 00:02:31.570
But when you compare this to percentage
values you see that a letter by itself

46
00:02:31.570 --> 00:02:35.270
covers 4% of the available grades and
that a letter with a plus or

47
00:02:35.270 --> 00:02:39.160
minus is usually just 3% of
the available grades.

48
00:02:39.160 --> 00:02:42.250
Based on this, it would be odd if there
were as many students who received

49
00:02:42.250 --> 00:02:45.420
an A plus or A minus as there
were who received a straight A.

50
00:02:46.980 --> 00:02:49.430
Ordinal data is very common
in machine learning and

51
00:02:49.430 --> 00:02:52.320
can sometimes be a challenge to work with.

52
00:02:52.320 --> 00:02:55.010
The last scale I'll mention
is the nominal scale which is

53
00:02:55.010 --> 00:02:57.450
often just called categorical data.

54
00:02:57.450 --> 00:03:00.500
Here the names of teams in
a sport might be good example.

55
00:03:00.500 --> 00:03:03.100
There are a limited number of teams but
changing their order or

56
00:03:03.100 --> 00:03:05.179
applying mathematical function
to them is meaningless.

57
00:03:06.240 --> 00:03:10.600
Categorical values are very common and
we generally refer to categories

58
00:03:10.600 --> 00:03:13.240
where there are only two
possible values as binary.

59
00:03:15.280 --> 00:03:19.500
So why did I stop talking about Pandas and
jump into this discussion of scale.

60
00:03:19.500 --> 00:03:21.685
Well, given how important
they are in statistics and

61
00:03:21.685 --> 00:03:24.555
machine learning, Pandas has
a number of interesting functions to

62
00:03:24.555 --> 00:03:27.735
deal with converting
between measurement scales.

63
00:03:27.735 --> 00:03:32.057
Let's start first with nominal data, which
in Pandas is called categorical data.

64
00:03:32.057 --> 00:03:35.363
Pandas actually has a built in type for
categorical data and you could

65
00:03:35.363 --> 00:03:39.497
set a column of your data to categorical
data by using the astype method.

66
00:03:39.497 --> 00:03:42.164
As type tries to change
the underlying type of your data,

67
00:03:42.164 --> 00:03:44.247
in this case to category data.

68
00:03:44.247 --> 00:03:48.117
You can further change this to ordinal
data by passing in an ordered flags set to

69
00:03:48.117 --> 00:03:51.900
true and passing in the categories
in an ordered fashion.

70
00:03:51.900 --> 00:03:52.595
Here's an example.

71
00:03:52.595 --> 00:03:56.210
Let's create a DataFrame of letter
grades in descending order.

72
00:03:56.210 --> 00:03:59.490
We can also set an index value of
some more course grain measure.

73
00:04:00.690 --> 00:04:04.630
Now when we instruct Pandas to render this
as categorical data, we see that the

74
00:04:04.630 --> 00:04:08.109
dtype has been set as category and
that there are 11 different categories.

75
00:04:09.284 --> 00:04:12.520
If we want to indicate to Pandas that
this data is in a logical order,

76
00:04:12.520 --> 00:04:15.030
we pass the ordered=True flag and

77
00:04:15.030 --> 00:04:19.430
we see thatâ€™s reflected in the category
dtype using the less than sign.

78
00:04:19.430 --> 00:04:20.860
What can you do with this?

79
00:04:20.860 --> 00:04:25.160
Well, ordinal data has ordering so
it can help you with the Boolean masking.

80
00:04:25.160 --> 00:04:28.540
For instance, if we have our list of
grades and we compared them with a C.

81
00:04:28.540 --> 00:04:31.860
If we did this lexographically,
we would that a C+ and

82
00:04:31.860 --> 00:04:33.980
a C- are both actually greater than a C.

83
00:04:35.560 --> 00:04:38.600
Instead of coding each of these to
something which is lexographical,

84
00:04:38.600 --> 00:04:42.500
like a number, we can indicate that
there's a clear order to the data.

85
00:04:42.500 --> 00:04:45.690
And then broadcasting
will work as we expect.

86
00:04:45.690 --> 00:04:49.120
We can then use a certain set of
mathematical operators like minimum,

87
00:04:49.120 --> 00:04:51.790
maximum and others on the ordinal data.

88
00:04:53.090 --> 00:04:57.710
Sometimes it's useful to represent
categorical values as each being a column

89
00:04:57.710 --> 00:05:01.760
with a true or a false as to
whether that category applies.

90
00:05:01.760 --> 00:05:04.560
This is especially common
in feature extraction,

91
00:05:04.560 --> 00:05:07.180
which is a topic in the third
course in this specialization.

92
00:05:08.690 --> 00:05:12.700
Variables with a Boolean value
are typically called dummy variables.

93
00:05:12.700 --> 00:05:15.540
And pandas has a built-in
function called get_dummies,

94
00:05:15.540 --> 00:05:20.100
which will convert the values of a single
column into multiple columns of 0's and

95
00:05:20.100 --> 00:05:22.909
1's, indicating the presence
of a dummy variable.

96
00:05:25.180 --> 00:05:28.048
There's one more function on scales
that I'd like to talk about.

97
00:05:28.048 --> 00:05:30.680
And that's on reducing a value
which is on the interval or

98
00:05:30.680 --> 00:05:36.560
ratio scale, like a number grade, into one
that is categorical like a letter grade.

99
00:05:36.560 --> 00:05:39.900
Now, this might seem a bit counter
intuitive to you since you're losing

100
00:05:39.900 --> 00:05:41.910
information about the value.

101
00:05:41.910 --> 00:05:43.956
But it's useful on a couple of places.

102
00:05:43.956 --> 00:05:47.550
First, if you're visualizing
the frequencies of categories, and

103
00:05:47.550 --> 00:05:50.100
this can be an extremely
useful approach and

104
00:05:50.100 --> 00:05:54.620
histograms are regularly used with
converted interval or ratio data.

105
00:05:54.620 --> 00:05:58.660
And we'll take a look at histograms in
the second course in this specialization.

106
00:06:00.160 --> 00:06:04.570
Second, if you're using a machine
learning classification approach on data,

107
00:06:04.570 --> 00:06:06.980
then you need to be
using categorical data.

108
00:06:06.980 --> 00:06:09.735
So reducing dimensionality
is useful there too.

109
00:06:09.735 --> 00:06:14.133
Pandas has a function called cut,
which takes an argument which is some array

110
00:06:14.133 --> 00:06:17.237
like structure of a column or
a DataFrame or a series.

111
00:06:17.237 --> 00:06:22.420
It also takes a number of bins to be used
and all bins are kept at equal spacing.

112
00:06:22.420 --> 00:06:25.270
Let's go back to our census data for
an example.

113
00:06:25.270 --> 00:06:26.920
We saw that we could group by state,

114
00:06:26.920 --> 00:06:30.650
then aggregate to get a list of
the average county size by state.

115
00:06:30.650 --> 00:06:34.830
If we further apply cut to this
with say 10 bins, we can see that

116
00:06:34.830 --> 00:06:39.500
the states listed as categoricals
using the average county size.

117
00:06:39.500 --> 00:06:44.000
Here we see the states like Alabama and
Alaska fall into the same category, while

118
00:06:44.000 --> 00:06:48.410
California and the District of Colombia
fall into a very different category.

119
00:06:48.410 --> 00:06:51.350
Now, cutting is just one way to
build categories from your data, and

120
00:06:51.350 --> 00:06:53.020
there's many other methods.

121
00:06:53.020 --> 00:06:54.932
For instance, cut gives you interval data,

122
00:06:54.932 --> 00:06:57.380
where the spacing between
each category is equal sized.

123
00:06:57.380 --> 00:07:00.940
But sometimes you want to form
categories based on frequency.

124
00:07:00.940 --> 00:07:03.230
You want the number of items
in each bin to be the same,

125
00:07:03.230 --> 00:07:05.650
instead of the spacing between bins.

126
00:07:05.650 --> 00:07:07.480
It really depends on
the shape of your data and

127
00:07:07.480 --> 00:07:08.740
what you're planning to do with it.

128
00:07:08.740 --> 00:07:11.760
And we'll look at some examples of this
in the graphing and charting course for

129
00:07:11.760 --> 00:07:13.820
those of you who are enrolled
in the specialization.

130
00:07:13.820 --> 00:07:16.880
That's it for this module of the course.

131
00:07:16.880 --> 00:07:20.060
There's a programming assignment to test
your knowledge of this module's content

132
00:07:20.060 --> 00:07:23.550
and I'll see you back in the next module
as a wrap up where we'll talk more

133
00:07:23.550 --> 00:07:26.910
about statistics and set up some basics
for comparing results of analysis.
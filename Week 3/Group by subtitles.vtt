WEBVTT

1
00:00:09.478 --> 00:00:13.042
We've seen that even though pandas allows
us to iterate over every row in a DataFrame

2
00:00:13.042 --> 00:00:15.904
this is generally a slow way
to accomplish a given task and

3
00:00:15.904 --> 00:00:17.950
it's not very pandorable.

4
00:00:17.950 --> 00:00:20.868
For instance, if we wanted to write
some code to iterate over all the of

5
00:00:20.868 --> 00:00:23.944
the states and generate a list of
the average census population numbers.

6
00:00:23.944 --> 00:00:27.370
We could do so
using a loop in the unique function.

7
00:00:27.370 --> 00:00:30.710
Another option is to use
the DataFrame groupby function.

8
00:00:30.710 --> 00:00:35.137
This function takes some column name or
names and splits the DataFrame up into

9
00:00:35.137 --> 00:00:39.170
chunks based on those names,
it returns a DataFrame groupby object.

10
00:00:39.170 --> 00:00:40.825
Which can be iterated upon, and

11
00:00:40.825 --> 00:00:44.197
then returns a tuple where the first
item is the group condition,

12
00:00:44.197 --> 00:00:48.100
and the second item is the data
frame reduced by that grouping.

13
00:00:48.100 --> 00:00:50.940
Since it's made up of two values,
you can unpack this, and

14
00:00:50.940 --> 00:00:54.220
project just the column that you're
interested in, to calculate the average.

15
00:00:56.290 --> 00:00:59.090
Here's some examples of
both methods in action.

16
00:00:59.090 --> 00:01:04.442
Let's first load the census data, then
exclude the state level summarizations,

17
00:01:04.442 --> 00:01:06.741
which had a sum level value of 40.

18
00:01:06.741 --> 00:01:09.905
Here's some examples of
both methods in action.

19
00:01:09.905 --> 00:01:13.911
Let's first load the census data,
then exclude the state level

20
00:01:13.911 --> 00:01:16.815
summarizations which
had a sum level of 40.

21
00:01:16.815 --> 00:01:19.135
In the first we used the census date.

22
00:01:19.135 --> 00:01:21.075
We get a list of the unique states.

23
00:01:21.075 --> 00:01:25.355
Then for each state we reduce the
DataFrame and calculate the average.

24
00:01:26.595 --> 00:01:28.695
If we time this we see it takes a while.

25
00:01:28.695 --> 00:01:31.605
I've set the number of loops here
the time it should take to ten

26
00:01:31.605 --> 00:01:32.465
because I'm live coding.

27
00:01:33.780 --> 00:01:36.800
Here's the same approach
with a groupby object.

28
00:01:36.800 --> 00:01:40.210
We tell pandas we're interested in
grouping by the state name and then we

29
00:01:40.210 --> 00:01:44.780
calculate the average using just one
column and all of the data in that column.

30
00:01:44.780 --> 00:01:47.100
When we time it we see a huge
difference in the speed

31
00:02:04.196 --> 00:02:08.248
Now, 99% of the time, you'll use
group by on one or more columns.

32
00:02:08.248 --> 00:02:11.375
But you can actually provide
a function to group by as well and

33
00:02:11.375 --> 00:02:13.760
use that to segment your data.

34
00:02:13.760 --> 00:02:15.910
This is a bit of a fabricated example but

35
00:02:15.910 --> 00:02:19.430
lets say that you have a big batch
job with lots of processing and

36
00:02:19.430 --> 00:02:23.210
you want to work on only a third or
so of the states at a given time.

37
00:02:23.210 --> 00:02:26.130
We could create some function which
returns a number between zero and

38
00:02:26.130 --> 00:02:29.530
two based on the first
character of the state name.

39
00:02:29.530 --> 00:02:33.300
Then we can tell group by to use this
function to split up our DataFrame.

40
00:02:33.300 --> 00:02:36.250
It's important to note that in order
to do this you need to set the index of

41
00:02:36.250 --> 00:02:38.970
the DataFrame to be the column
that you want to group by first.

42
00:02:40.810 --> 00:02:41.930
Here's an example.

43
00:02:41.930 --> 00:02:44.301
We'll create some new
function called fun and

44
00:02:44.301 --> 00:02:47.840
if the first letter of the parameter
is a capital M we'll return a 0.

45
00:02:47.840 --> 00:02:52.010
If it's a capital Q we'll return a 1 and
otherwise we'll return a 2.

46
00:02:52.010 --> 00:02:54.620
Then we'll pass this function
to the DataFrame apply, and

47
00:02:54.620 --> 00:02:58.470
see that the DataFrame is segmented
by the calculated group number.

48
00:02:58.470 --> 00:03:01.753
This kind of technique,
which is sort of a light weight hashing,

49
00:03:01.753 --> 00:03:04.989
is commonly used to distribute
tasks across multiple workers.

50
00:03:04.989 --> 00:03:09.690
Whether they are cores in a processor,
nodes in a supercomputer, or

51
00:03:09.690 --> 00:03:11.156
disks in a database.

52
00:03:11.156 --> 00:03:14.381
A common work flow with groupby
is that you split your data,

53
00:03:14.381 --> 00:03:17.540
you apply some function,
then you combine the results.

54
00:03:17.540 --> 00:03:19.548
This is called split
apply combine pattern.

55
00:03:19.548 --> 00:03:22.840
And we've seen the splitting method,
but what about apply?

56
00:03:22.840 --> 00:03:25.900
Certainly iterative methods as
we've seen can do this, but

57
00:03:25.900 --> 00:03:30.890
the groupby object also has a method
called agg which is short for aggregate.

58
00:03:30.890 --> 00:03:33.030
This method applies
a function to the column or

59
00:03:33.030 --> 00:03:35.460
columns of data in the group,
and returns the results.

60
00:03:36.600 --> 00:03:40.650
With agg, you simply pass in a dictionary
of the column names that you're interested

61
00:03:40.650 --> 00:03:43.140
in, and
the function that you want to apply.

62
00:03:43.140 --> 00:03:46.720
For instance to build a summary DataFrame
for the average populations per state,

63
00:03:46.720 --> 00:03:51.304
we could just give agg a dictionary
with the Census 2010 pop key and

64
00:03:51.304 --> 00:03:59.110
the NumPy average function.

65
00:04:03.496 --> 00:04:05.393
Now, I want to flag a potential issue in

66
00:04:05.393 --> 00:04:07.860
using the aggregate method
of group by objects.

67
00:04:07.860 --> 00:04:10.930
You see, when you pass in a dictionary
it can be used to either to identify

68
00:04:10.930 --> 00:04:13.160
the columns to apply a function on or

69
00:04:13.160 --> 00:04:16.980
to name an output column if there's
multiple functions to be run.

70
00:04:16.980 --> 00:04:20.950
The difference depends on the keys that
you pass in from the dictionary and

71
00:04:20.950 --> 00:04:21.520
how they're named.

72
00:04:22.570 --> 00:04:26.230
In short, while much of the documentation
and examples will talk about a single

73
00:04:26.230 --> 00:04:29.190
groupby object,
there's really two different objects.

74
00:04:29.190 --> 00:04:31.584
The DataFrame groupby and
the series groupby.

75
00:04:31.584 --> 00:04:34.499
And these objects behave a little
bit differently with aggregate.

76
00:04:35.580 --> 00:04:39.700
For instance, we take our census data and
convert it into a series with the state

77
00:04:39.700 --> 00:04:44.110
names as the index and only columns
as the census 2010 population.

78
00:04:44.110 --> 00:04:47.860
And then we can group this by
index using the level parameter.

79
00:04:47.860 --> 00:04:50.800
Then we call the agg method where
the dictionary that has both the NumPy

80
00:04:50.800 --> 00:04:53.445
average and the NumPy sum functions.

81
00:04:53.445 --> 00:04:57.317
Pandas applies those functions to the
series object and, since there's only one

82
00:04:57.317 --> 00:05:01.145
column of data, it apples both functions
to that column and prints out the output.

83
00:05:14.743 --> 00:05:17.750
We can do the same thing with
a DataFrame instead of a series.

84
00:05:17.750 --> 00:05:20.890
We set the index to be the state name,
we group by the index, and

85
00:05:20.890 --> 00:05:22.540
we project two columns.

86
00:05:22.540 --> 00:05:26.830
The population estimate in 2010,
and the population estimate in 2011.

87
00:05:26.830 --> 00:05:28.969
When we call aggregate
with two parameters,

88
00:05:28.969 --> 00:05:33.670
it builds a nice hierarchical column space
and all of our functions are applied.

89
00:05:33.670 --> 00:05:37.630
Where the confusion can come in is when
we change the labels of the dictionary we

90
00:05:37.630 --> 00:05:41.980
passed to aggregate, to correspond to
the labels in our group DataFrame.

91
00:05:41.980 --> 00:05:46.050
In this case, pandas recognizes that
they're the same and maps the functions

92
00:05:46.050 --> 00:05:50.620
directly to columns instead of creating
a hierarchically labeled column.

93
00:05:50.620 --> 00:05:52.980
From my perspective this
is very odd behavior,

94
00:05:52.980 --> 00:05:55.770
not what I would expect
given the labeling change.

95
00:05:55.770 --> 00:05:58.510
So just be aware of this when
using the aggregate function.

96
00:05:59.690 --> 00:06:01.360
So that's the groupby function.

97
00:06:01.360 --> 00:06:05.390
I use the groupby function regularly
in my work, and it's very handy for

98
00:06:05.390 --> 00:06:08.650
segmenting a DataFrame,
working on small pieces of the DataFrame,

99
00:06:08.650 --> 00:06:10.980
and then creating bigger
DataFrames later.